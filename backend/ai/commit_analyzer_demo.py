#!/usr/bin/env python3
"""
Commit Analyzer Demo - No Torch Version
Ph√¢n t√≠ch commit messages s·ª≠ d·ª•ng k·∫øt qu·∫£ ƒë√£ c√≥ c·ªßa m√¥ h√¨nh multimodal fusion
"""

import json
import argparse
from datetime import datetime
from pathlib import Path

class CommitAnalyzerDemo:
    """
    Demo version c·ªßa commit analyzer s·ª≠ d·ª•ng k·∫øt qu·∫£ evaluation c√≥ s·∫µn
    """
    
    def __init__(self):
        """Initialize v·ªõi evaluation results c√≥ s·∫µn"""
        self.base_path = Path("d:/Project/KLTN04/backend/ai")
        self.evaluation_data = self._load_evaluation_data()
        self.model_info = self._load_model_info()
        
    def _load_evaluation_data(self):
        """Load evaluation results t·ª´ file JSON"""
        eval_file = self.base_path / "evaluation_results" / "multimodal_fusion_simple_report.json"
        
        if eval_file.exists():
            try:
                with open(eval_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"‚ùå Error loading evaluation data: {e}")
                return {}
        else:
            print(f"‚ùå Evaluation file not found: {eval_file}")
            return {}
    
    def _load_model_info(self):
        """Load th√¥ng tin model t·ª´ documentation"""
        model_info = {
            "total_parameters": "2.15M",
            "architecture": "Multimodal Fusion Network",
            "components": {
                "text_branch": "LSTM/Transformer (1.8M params - 83.8%)",
                "metadata_branch": "Dense layers (125K params - 5.8%)", 
                "fusion_layer": "Cross-attention (182K params - 8.4%)",
                "task_heads": "4 classification heads (42K params - 1.9%)"
            },
            "tasks": {
                "complexity_prediction": "3 classes (Low/Medium/High)",
                "risk_prediction": "2 classes (Safe/Risky)", 
                "hotspot_prediction": "5 classes (Critical/High/Medium/Low/Normal)",
                "urgency_prediction": "2 classes (Normal/Urgent)"
            }
        }
        return model_info
    
    def display_model_architecture(self):
        """Hi·ªÉn th·ªã th√¥ng tin ki·∫øn tr√∫c model"""
        print("\n" + "="*80)
        print("üèóÔ∏è  MULTIMODAL FUSION MODEL ARCHITECTURE")
        print("="*80)
        
        print(f"\nüìä Model Type: {self.model_info['architecture']}")
        print(f"üìà Total Parameters: {self.model_info['total_parameters']}")
        
        print(f"\nüß© COMPONENTS:")
        print("-" * 50)
        for component, description in self.model_info['components'].items():
            print(f"  ‚Ä¢ {component.replace('_', ' ').title()}: {description}")
        
        print(f"\nüéØ CLASSIFICATION TASKS:")
        print("-" * 50)
        for task, description in self.model_info['tasks'].items():
            print(f"  ‚Ä¢ {task.replace('_', ' ').title()}: {description}")
    
    def display_performance_summary(self):
        """Hi·ªÉn th·ªã t√≥m t·∫Øt hi·ªáu su·∫•t model"""
        print("\n" + "="*80)
        print("üìà MODEL PERFORMANCE SUMMARY")
        print("="*80)
        
        if not self.evaluation_data:
            print("‚ùå No evaluation data available")
            return
        
        perf = self.evaluation_data.get('performance_metrics', {})
        summary = self.evaluation_data.get('summary_metrics', {})
        
        print(f"\nüìä OVERALL METRICS:")
        print("-" * 50)
        print(f"  ‚Ä¢ Average F1 Score: {summary.get('average_f1_score', 0):.4f}")
        print(f"  ‚Ä¢ Best Task: {summary.get('best_performing_task', 'N/A')}")
        print(f"  ‚Ä¢ Worst Task: {summary.get('worst_performing_task', 'N/A')}")
        
        print(f"\nüéØ TASK-SPECIFIC PERFORMANCE:")
        print("-" * 50)
        for task, f1_score in summary.get('task_f1_scores', {}).items():
            task_name = task.replace('_', ' ').title()
            status = "üü¢" if f1_score > 0.3 else "üü°" if f1_score > 0.05 else "üî¥"
            print(f"  {status} {task_name}: F1 = {f1_score:.4f}")
    
    def analyze_sample_commit(self, commit_message: str = None):
        """Ph√¢n t√≠ch m·ªôt commit message m·∫´u"""
        
        if not commit_message:
            # Demo v·ªõi commit message m·∫´u
            commit_message = "Fix critical bug in user authentication module that could lead to security vulnerability"
        
        print("\n" + "="*80)
        print("üîç COMMIT MESSAGE ANALYSIS")
        print("="*80)
        
        print(f"\nüìù Commit Message:")
        print(f"  \"{commit_message}\"")
        
        # Ph√¢n t√≠ch ƒë∆°n gi·∫£n d·ª±a tr√™n keywords
        analysis = self._simple_keyword_analysis(commit_message)
        
        print(f"\nü§ñ AI ANALYSIS (Based on Model Pattern):")
        print("-" * 50)
        
        for task, prediction in analysis.items():
            task_name = task.replace('_', ' ').title()
            confidence = prediction['confidence']
            result = prediction['prediction']
            confidence_bar = "‚ñà" * int(confidence * 10) + "‚ñë" * (10 - int(confidence * 10))
            
            print(f"  ‚Ä¢ {task_name}:")
            print(f"    Prediction: {result}")
            print(f"    Confidence: [{confidence_bar}] {confidence:.1%}")
    
    def _simple_keyword_analysis(self, commit_message: str):
        """Ph√¢n t√≠ch ƒë∆°n gi·∫£n d·ª±a tr√™n keywords"""
        msg_lower = commit_message.lower()
        
        # Keyword patterns d·ª±a tr√™n ph√¢n t√≠ch th·ª±c t·∫ø
        analysis = {
            'complexity_prediction': {
                'prediction': 'Medium',
                'confidence': 0.7
            },
            'risk_prediction': {
                'prediction': 'Safe', 
                'confidence': 0.6
            },
            'hotspot_prediction': {
                'prediction': 'Normal',
                'confidence': 0.5
            },
            'urgency_prediction': {
                'prediction': 'Normal',
                'confidence': 0.8
            }
        }
        
        # Adjust based on keywords
        high_risk_keywords = ['critical', 'security', 'vulnerability', 'bug', 'crash', 'error']
        high_complexity_keywords = ['refactor', 'architecture', 'major', 'overhaul', 'redesign']
        urgent_keywords = ['hotfix', 'urgent', 'critical', 'emergency', 'asap']
        hotspot_keywords = ['auth', 'login', 'payment', 'database', 'api', 'core']
        
        # Risk analysis
        if any(keyword in msg_lower for keyword in high_risk_keywords):
            analysis['risk_prediction']['prediction'] = 'Risky'
            analysis['risk_prediction']['confidence'] = 0.8
        
        # Complexity analysis  
        if any(keyword in msg_lower for keyword in high_complexity_keywords):
            analysis['complexity_prediction']['prediction'] = 'High'
            analysis['complexity_prediction']['confidence'] = 0.8
        elif len(commit_message.split()) > 10:
            analysis['complexity_prediction']['prediction'] = 'Medium'
            analysis['complexity_prediction']['confidence'] = 0.7
        else:
            analysis['complexity_prediction']['prediction'] = 'Low'
            analysis['complexity_prediction']['confidence'] = 0.6
        
        # Urgency analysis
        if any(keyword in msg_lower for keyword in urgent_keywords):
            analysis['urgency_prediction']['prediction'] = 'Urgent'
            analysis['urgency_prediction']['confidence'] = 0.9
        
        # Hotspot analysis
        if any(keyword in msg_lower for keyword in hotspot_keywords):
            analysis['hotspot_prediction']['prediction'] = 'High'
            analysis['hotspot_prediction']['confidence'] = 0.7
        
        return analysis
    
    def interactive_mode(self):
        """Ch·∫ø ƒë·ªô interactive ƒë·ªÉ ph√¢n t√≠ch commits"""
        print("\n" + "="*80)
        print("ü§ñ INTERACTIVE COMMIT ANALYZER")
        print("="*80)
        print("Enter commit messages to analyze (type 'quit' to exit)")
        print("-" * 50)
        
        while True:
            try:
                commit_msg = input("\nüìù Enter commit message: ").strip()
                
                if commit_msg.lower() in ['quit', 'exit', 'q']:
                    print("\nüëã Goodbye!")
                    break
                
                if not commit_msg:
                    print("‚ùå Please enter a commit message")
                    continue
                
                self.analyze_sample_commit(commit_msg)
                
            except KeyboardInterrupt:
                print("\n\nüëã Goodbye!")
                break
            except Exception as e:
                print(f"‚ùå Error: {e}")
    
    def display_model_insights(self):
        """Hi·ªÉn th·ªã insights v·ªÅ model"""
        print("\n" + "="*80)
        print("üí° MODEL INSIGHTS & RECOMMENDATIONS")
        print("="*80)
        
        print(f"\nüîç CURRENT STATUS:")
        print("-" * 50)
        print("  ‚Ä¢ Model has 2.15M parameters with 4 classification heads")
        print("  ‚Ä¢ Text processing dominates (83.8% of parameters)")
        print("  ‚Ä¢ Cross-attention fusion mechanism implemented")
        print("  ‚Ä¢ Severe class imbalance in training data")
        
        print(f"\n‚ö†Ô∏è  MAIN ISSUES:")
        print("-" * 50)
        print("  ‚Ä¢ Task heads appear to be randomly initialized (not trained)")
        print("  ‚Ä¢ Urgency task shows 0% performance (100% normal class)")
        print("  ‚Ä¢ Hotspot detection near-zero performance (98% normal class)")
        print("  ‚Ä¢ Only complexity task shows reasonable performance (F1: 0.41)")
        
        print(f"\nüöÄ IMPROVEMENT RECOMMENDATIONS:")
        print("-" * 50)
        print("  1. Implement proper end-to-end training pipeline")
        print("  2. Address severe class imbalance with:")
        print("     - Data augmentation for minority classes")
        print("     - Weighted loss functions")
        print("     - SMOTE or similar techniques")
        print("  3. Collect more diverse training data")
        print("  4. Fine-tune pre-trained embeddings")
        print("  5. Implement proper validation and early stopping")

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Multimodal Fusion Commit Analyzer Demo")
    parser.add_argument('--demo', action='store_true', help='Run demo mode')
    parser.add_argument('--interactive', action='store_true', help='Run interactive mode')
    parser.add_argument('--analysis', action='store_true', help='Show model analysis')
    parser.add_argument('--message', type=str, help='Analyze specific commit message')
    
    args = parser.parse_args()
    
    analyzer = CommitAnalyzerDemo()
    
    if args.demo or (not args.interactive and not args.analysis and not args.message):
        # Default demo mode
        analyzer.display_model_architecture()
        analyzer.display_performance_summary()
        analyzer.analyze_sample_commit()
        analyzer.display_model_insights()
        
    elif args.interactive:
        analyzer.display_model_architecture()
        analyzer.display_performance_summary()
        analyzer.interactive_mode()
        
    elif args.analysis:
        analyzer.display_model_architecture()
        analyzer.display_performance_summary()
        analyzer.display_model_insights()
        
    elif args.message:
        analyzer.display_model_architecture()
        analyzer.analyze_sample_commit(args.message)

if __name__ == "__main__":
    main()
