"""
TÃ¬m kiáº¿m vÃ  download cÃ¡c dataset commit messages cÃ³ sáºµn trÃªn Kaggle
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime
from pathlib import Path

def setup_kaggle_api():
    """Setup Kaggle API"""
    try:
        import kaggle
        from kaggle.api.kaggle_api_extended import KaggleApi
        
        api = KaggleApi()
        api.authenticate()
        return api
    except Exception as e:
        print(f"âŒ Lá»—i setup Kaggle API: {e}")
        return None

def search_commit_datasets(api):
    """TÃ¬m kiáº¿m datasets vá» commit messages"""
    try:
        print("ğŸ” TÃŒNG KIáº¾M DATASETS Vá»€ COMMIT MESSAGES")
        print("="*60)
        
        # TÃ¬m kiáº¿m vá»›i tá»« khÃ³a khÃ¡c nhau
        search_terms = ['commit', 'git commit', 'github commit', 'commit message', 'git']
        all_datasets = []
        
        for term in search_terms:
            print(f"\nğŸ” TÃ¬m kiáº¿m: '{term}'")
            try:
                datasets = api.dataset_list(search=term, page_size=10)
                for dataset in datasets:
                    # Lá»c nhá»¯ng dataset cÃ³ váº» liÃªn quan Ä‘áº¿n commit
                    title_lower = dataset.title.lower()
                    ref_lower = dataset.ref.lower()
                    
                    if any(keyword in title_lower or keyword in ref_lower 
                           for keyword in ['commit', 'git', 'github', 'message']):
                        
                        dataset_info = {
                            'ref': dataset.ref,
                            'title': dataset.title,
                            'size': dataset.totalBytes,
                            'downloads': dataset.downloadCount,
                            'files': dataset.fileCount,
                            'license': dataset.licenseName,
                            'updated': dataset.lastUpdated
                        }
                        
                        # Kiá»ƒm tra duplicate
                        if not any(d['ref'] == dataset_info['ref'] for d in all_datasets):
                            all_datasets.append(dataset_info)
                            
            except Exception as e:
                print(f"  âš ï¸ Lá»—i tÃ¬m kiáº¿m '{term}': {e}")
        
        # Sáº¯p xáº¿p theo downloads
        all_datasets.sort(key=lambda x: x['downloads'], reverse=True)
        
        print(f"\nğŸ“‹ TÃŒNG THáº¤Y {len(all_datasets)} DATASETS:")
        print("="*80)
        
        for i, dataset in enumerate(all_datasets[:15], 1):  # Top 15
            size_mb = dataset['size'] / (1024*1024) if dataset['size'] else 0
            print(f"{i:2d}. {dataset['ref']}")
            print(f"    ğŸ“„ {dataset['title']}")
            print(f"    ğŸ“Š {dataset['downloads']:,} downloads | {size_mb:.1f} MB | {dataset['files']} files")
            print(f"    ğŸ“… Updated: {dataset['updated']}")
            print()
        
        return all_datasets
        
    except Exception as e:
        print(f"âŒ Lá»—i tÃ¬m kiáº¿m datasets: {e}")
        return []

def test_dataset_access(api, dataset_ref):
    """Test xem cÃ³ thá»ƒ download dataset khÃ´ng"""
    try:
        print(f"ğŸ” Testing access: {dataset_ref}")
        
        # Thá»­ láº¥y thÃ´ng tin files
        files = api.dataset_list_files(dataset_ref)
        print(f"  âœ… Files accessible: {len(files)}")
        
        for file in files[:3]:  # Show first 3 files
            size_mb = file.totalBytes / (1024*1024) if file.totalBytes else 0
            print(f"    ğŸ“„ {file.name} ({size_mb:.1f} MB)")
        
        return True, files
        
    except Exception as e:
        print(f"  âŒ Access denied: {e}")
        return False, []

def download_and_preview_dataset(api, dataset_ref, max_preview_rows=1000):
    """Download vÃ  preview dataset"""
    try:
        print(f"\nğŸ“¥ DOWNLOADING: {dataset_ref}")
        print("="*60)
        
        # Táº¡o thÆ° má»¥c download
        download_dir = Path(__file__).parent / "kaggle_data" / dataset_ref.replace('/', '_')
        download_dir.mkdir(parents=True, exist_ok=True)
        
        # Download
        print(f"ğŸ“ Download to: {download_dir}")
        api.dataset_download_files(dataset_ref, path=str(download_dir), unzip=True)
        
        # TÃ¬m files CSV/JSON
        csv_files = list(download_dir.glob("*.csv"))
        json_files = list(download_dir.glob("*.json"))
        txt_files = list(download_dir.glob("*.txt"))
        
        print(f"ğŸ“‹ Files downloaded:")
        all_files = csv_files + json_files + txt_files
        for file in all_files:
            size_mb = file.stat().st_size / (1024*1024)
            print(f"  ğŸ“„ {file.name} ({size_mb:.1f} MB)")
        
        # Preview CSV files
        for csv_file in csv_files[:2]:  # Preview first 2 CSV files
            try:
                print(f"\nğŸ“Š PREVIEW: {csv_file.name}")
                print("-"*50)
                
                # Read sample
                df = pd.read_csv(csv_file, nrows=max_preview_rows)
                print(f"Shape: {df.shape}")
                print(f"Columns: {list(df.columns)}")
                
                # Look for commit-related columns
                commit_cols = []
                for col in df.columns:
                    col_lower = col.lower()
                    if any(keyword in col_lower for keyword in 
                           ['message', 'commit', 'subject', 'title', 'description']):
                        commit_cols.append(col)
                
                if commit_cols:
                    print(f"ğŸ¯ Potential commit columns: {commit_cols}")
                    
                    # Show samples
                    for col in commit_cols[:2]:
                        print(f"\nSample {col}:")
                        samples = df[col].dropna().head(5)
                        for i, sample in enumerate(samples, 1):
                            sample_str = str(sample)[:100]
                            print(f"  {i}. {sample_str}{'...' if len(str(sample)) > 100 else ''}")
                
                print(f"âœ… {csv_file.name} looks promising for commit data")
                
            except Exception as e:
                print(f"âš ï¸ Error previewing {csv_file.name}: {e}")
        
        return download_dir, all_files
        
    except Exception as e:
        print(f"âŒ Download failed: {e}")
        return None, []

def main():
    """Main function"""
    print("ğŸ” KAGGLE COMMIT DATASETS FINDER")
    print("="*60)
    
    # Setup API
    api = setup_kaggle_api()
    if not api:
        return
    
    # Search datasets
    datasets = search_commit_datasets(api)
    if not datasets:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y datasets phÃ¹ há»£p")
        return
    
    # Let user choose
    print("\nğŸ¯ CHá»ŒN DATASET Äá»‚ DOWNLOAD:")
    print("0. Exit")
    for i, dataset in enumerate(datasets[:10], 1):
        print(f"{i}. {dataset['ref']} ({dataset['downloads']:,} downloads)")
    
    choice = input("\nNháº­p sá»‘ dataset muá»‘n download (0-10): ").strip()
    
    if choice == '0' or not choice.isdigit():
        print("ğŸ‘‹ Goodbye!")
        return
    
    try:
        idx = int(choice) - 1
        if 0 <= idx < min(10, len(datasets)):
            selected = datasets[idx]
            dataset_ref = selected['ref']
            
            print(f"\nâœ¨ ÄÃƒ CHá»ŒN: {dataset_ref}")
            
            # Test access
            accessible, files = test_dataset_access(api, dataset_ref)
            if not accessible:
                print("âŒ Dataset khÃ´ng thá»ƒ truy cáº­p")
                return
            
            # Download and preview
            download_dir, downloaded_files = download_and_preview_dataset(api, dataset_ref)
            
            if download_dir and downloaded_files:
                print(f"\nğŸ‰ THÃ€NH CÃ”NG!")
                print(f"ğŸ“ Data downloaded to: {download_dir}")
                print(f"ğŸ“‹ BÃ¢y giá» báº¡n cÃ³ thá»ƒ:")
                print(f"  â€¢ Kiá»ƒm tra files trong {download_dir}")
                print(f"  â€¢ Sá»­ dá»¥ng data Ä‘á»ƒ train model")
                
                # Suggestion for next steps
                csv_files = [f for f in downloaded_files if f.suffix == '.csv']
                if csv_files:
                    print(f"\nğŸ’¡ Äá»€ XUáº¤T:")
                    print(f"  Sá»­ dá»¥ng file CSV chÃ­nh: {csv_files[0].name}")
                    print(f"  CÃ³ thá»ƒ train model vá»›i data nÃ y")
            
        else:
            print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡")
            
    except ValueError:
        print("âŒ Vui lÃ²ng nháº­p sá»‘ há»£p lá»‡")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

if __name__ == "__main__":
    main()
