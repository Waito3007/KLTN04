#!/usr/bin/env python3
"""
Script tÃ­ch há»£p Ä‘á»ƒ táº£i dá»¯ liá»‡u tá»« Kaggle vÃ  train mÃ´ hÃ¬nh HAN
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path

# Add backend directory to path
backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, backend_dir)

# Import cÃ¡c module cáº§n thiáº¿t
from download_kaggle_dataset import KaggleDatasetDownloader

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HANKaggleTrainer:
    def __init__(self, base_dir: str = None):
        """
        Khá»Ÿi táº¡o trainer tÃ­ch há»£p Kaggle + HAN
        
        Args:
            base_dir: ThÆ° má»¥c gá»‘c cá»§a project
        """
        self.base_dir = base_dir or os.path.dirname(__file__)
        self.downloader = KaggleDatasetDownloader(self.base_dir)
        
    def prepare_data_from_kaggle(self, dataset_names: list = None, merge_files: bool = True) -> str:
        """
        Táº£i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u tá»« Kaggle
        
        Args:
            dataset_names: Danh sÃ¡ch tÃªn dataset
            merge_files: CÃ³ gá»™p files khÃ´ng
            
        Returns:
            str: ÄÆ°á»ng dáº«n file dá»¯ liá»‡u cuá»‘i cÃ¹ng
        """
        logger.info("ğŸ”„ Báº¯t Ä‘áº§u táº£i dá»¯ liá»‡u tá»« Kaggle...")
        
        # Táº£i vÃ  xá»­ lÃ½ datasets
        processed_files = self.downloader.download_and_process_datasets(dataset_names)
        
        if not processed_files:
            raise Exception("KhÃ´ng thá»ƒ táº£i Ä‘Æ°á»£c dá»¯ liá»‡u nÃ o tá»« Kaggle")
        
        # Gá»™p files náº¿u cáº§n
        if merge_files and len(processed_files) > 1:
            logger.info("ğŸ”„ Gá»™p cÃ¡c files dá»¯ liá»‡u...")
            final_file = self.downloader.merge_datasets(processed_files)
        else:
            final_file = processed_files[0]
        
        logger.info(f"âœ… Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng: {final_file}")
        return final_file
    
    def validate_data_for_han(self, data_file: str) -> bool:
        """
        Kiá»ƒm tra dá»¯ liá»‡u cÃ³ phÃ¹ há»£p vá»›i HAN model khÃ´ng
        
        Args:
            data_file: ÄÆ°á»ng dáº«n file dá»¯ liá»‡u
            
        Returns:
            bool: True náº¿u dá»¯ liá»‡u há»£p lá»‡
        """
        try:
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Kiá»ƒm tra cáº¥u trÃºc
            if 'data' not in data:
                logger.error("âŒ Thiáº¿u trÆ°á»ng 'data' trong file")
                return False
            
            if not data['data']:
                logger.error("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u trong file")
                return False
            
            # Kiá»ƒm tra sample Ä‘áº§u tiÃªn
            first_sample = data['data'][0]
            required_fields = ['text', 'labels']
            
            for field in required_fields:
                if field not in first_sample:
                    logger.error(f"âŒ Thiáº¿u trÆ°á»ng '{field}' trong sample")
                    return False
            
            # Kiá»ƒm tra labels
            labels = first_sample['labels']
            required_labels = ['commit_type', 'purpose', 'sentiment', 'tech_tag']
            
            for label in required_labels:
                if label not in labels:
                    logger.warning(f"âš ï¸ Thiáº¿u label '{label}' - sáº½ Ä‘Æ°á»£c thÃªm giÃ¡ trá»‹ máº·c Ä‘á»‹nh")
            
            logger.info("âœ… Dá»¯ liá»‡u há»£p lá»‡ cho HAN model")
            
            # In thá»‘ng kÃª
            total_samples = len(data['data'])
            logger.info(f"ğŸ“Š Tá»•ng sá»‘ samples: {total_samples}")
            
            if 'metadata' in data and 'statistics' in data['metadata']:
                stats = data['metadata']['statistics']
                logger.info("ğŸ“Š Thá»‘ng kÃª nhÃ£n:")
                for label_type, counts in stats.items():
                    if isinstance(counts, dict):
                        logger.info(f"  {label_type}: {dict(list(counts.items())[:5])}")  # Top 5
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i khi kiá»ƒm tra dá»¯ liá»‡u: {e}")
            return False
    
    def create_han_training_config(self, data_file: str) -> dict:
        """
        Táº¡o cáº¥u hÃ¬nh training cho HAN model
        
        Args:
            data_file: ÄÆ°á»ng dáº«n file dá»¯ liá»‡u
            
        Returns:
            dict: Cáº¥u hÃ¬nh training
        """
        # Load data Ä‘á»ƒ tÃ­nh toÃ¡n cáº¥u hÃ¬nh
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        total_samples = len(data['data'])
        
        # TÃ­nh toÃ¡n batch size vÃ  epochs phÃ¹ há»£p
        if total_samples < 1000:
            batch_size = 16
            epochs = 50
        elif total_samples < 10000:
            batch_size = 32
            epochs = 30
        else:
            batch_size = 64
            epochs = 20
        
        config = {
            'data_file': data_file,
            'model_config': {
                'vocab_size': 10000,
                'embedding_dim': 100,
                'hidden_dim': 128,
                'num_classes': {
                    'commit_type': 9,  # feat, fix, docs, style, refactor, test, chore, other
                    'purpose': 9,      # Feature Implementation, Bug Fix, etc.
                    'sentiment': 4,    # positive, negative, neutral, urgent
                    'tech_tag': 16,    # javascript, python, etc.
                },
                'dropout': 0.3
            },
            'training_config': {
                'batch_size': batch_size,
                'epochs': epochs,
                'learning_rate': 0.001,
                'weight_decay': 1e-4,
                'val_split': 0.2,
                'early_stopping_patience': 5
            },
            'output_config': {
                'model_dir': os.path.join(self.base_dir, 'models', 'han_kaggle_model'),
                'log_dir': os.path.join(self.base_dir, 'training_logs'),
                'checkpoint_dir': os.path.join(self.base_dir, 'checkpoints')
            }
        }
        
        # Táº¡o thÆ° má»¥c output
        for dir_path in config['output_config'].values():
            os.makedirs(dir_path, exist_ok=True)
        
        return config
    
    def start_han_training(self, config: dict) -> bool:
        """
        Báº¯t Ä‘áº§u training HAN model
        
        Args:
            config: Cáº¥u hÃ¬nh training
            
        Returns:
            bool: True náº¿u training thÃ nh cÃ´ng
        """
        try:
            logger.info("ğŸš€ Báº¯t Ä‘áº§u training HAN model...")
            
            # Import HAN training module
            try:
                from train_han_multitask import main as train_han_main
                
                # Cáº­p nháº­t config cho HAN trainer
                # CÃ³ thá»ƒ cáº§n modify train_han_multitask.py Ä‘á»ƒ cháº¥p nháº­n config tá»« bÃªn ngoÃ i
                
                # Táº¡m thá»i cháº¡y script trá»±c tiáº¿p
                import subprocess
                
                script_path = os.path.join(self.base_dir, 'train_han_multitask.py')
                result = subprocess.run([
                    sys.executable, script_path
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    logger.info("âœ… Training HAN model thÃ nh cÃ´ng!")
                    return True
                else:
                    logger.error(f"âŒ Lá»—i khi training: {result.stderr}")
                    return False
                    
            except ImportError:
                logger.error("âŒ KhÃ´ng thá»ƒ import HAN training module")
                logger.info("ğŸ’¡ HÃ£y Ä‘áº£m báº£o file train_han_multitask.py tá»“n táº¡i")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Lá»—i khi training HAN model: {e}")
            return False
    
    def run_full_pipeline(self, dataset_names: list = None) -> bool:
        """
        Cháº¡y toÃ n bá»™ pipeline tá»« táº£i dá»¯ liá»‡u Ä‘áº¿n training
        
        Args:
            dataset_names: Danh sÃ¡ch dataset cáº§n táº£i
            
        Returns:
            bool: True náº¿u thÃ nh cÃ´ng
        """
        try:
            logger.info("ğŸ¯ Báº®T Äáº¦U FULL PIPELINE KAGGLE + HAN")
            logger.info("=" * 60)
            
            # BÆ°á»›c 1: Táº£i dá»¯ liá»‡u tá»« Kaggle
            logger.info("ğŸ“¦ BÆ¯á»šC 1: Táº£i dá»¯ liá»‡u tá»« Kaggle")
            data_file = self.prepare_data_from_kaggle(dataset_names)
            
            # BÆ°á»›c 2: Kiá»ƒm tra dá»¯ liá»‡u
            logger.info("ğŸ” BÆ¯á»šC 2: Kiá»ƒm tra dá»¯ liá»‡u")
            if not self.validate_data_for_han(data_file):
                return False
            
            # BÆ°á»›c 3: Táº¡o cáº¥u hÃ¬nh training
            logger.info("âš™ï¸ BÆ¯á»šC 3: Táº¡o cáº¥u hÃ¬nh training")
            config = self.create_han_training_config(data_file)
            
            # LÆ°u cáº¥u hÃ¬nh
            config_file = os.path.join(self.base_dir, f'han_training_config_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u cáº¥u hÃ¬nh: {config_file}")
            
            # BÆ°á»›c 4: Training model
            logger.info("ğŸš€ BÆ¯á»šC 4: Training HAN model")
            training_success = self.start_han_training(config)
            
            if training_success:
                logger.info("ğŸ‰ PIPELINE HOÃ€N THÃ€NH THÃ€NH CÃ”NG!")
                logger.info(f"ğŸ“Š Dá»¯ liá»‡u: {data_file}")
                logger.info(f"âš™ï¸ Cáº¥u hÃ¬nh: {config_file}")
                logger.info(f"ğŸ¤– Model: {config['output_config']['model_dir']}")
                return True
            else:
                logger.error("âŒ PIPELINE THáº¤T Báº I á» BÆ¯á»šC TRAINING")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Lá»–I TRONG PIPELINE: {e}")
            return False

def main():
    """HÃ m chÃ­nh"""
    print("ğŸ¯ HAN MODEL TRAINING Vá»šI KAGGLE DATASET")
    print("=" * 80)
    
    trainer = HANKaggleTrainer()
    
    # Menu lá»±a chá»n
    print("\nğŸ“‹ CÃ¡c tÃ¹y chá»n:")
    print("1. Cháº¡y full pipeline (táº£i dá»¯ liá»‡u + training)")
    print("2. Chá»‰ táº£i dá»¯ liá»‡u tá»« Kaggle")
    print("3. Training vá»›i dá»¯ liá»‡u cÃ³ sáºµn")
    print("4. Kiá»ƒm tra dá»¯ liá»‡u hiá»‡n cÃ³")
    
    choice = input("\nğŸ”¸ Chá»n tÃ¹y chá»n (1-4): ").strip()
    
    if choice == '1':
        # Full pipeline
        print("\nğŸ”¸ Chá»n loáº¡i dataset:")
        print("1. Táº¥t cáº£ datasets phá»• biáº¿n")
        print("2. Dataset cá»¥ thá»ƒ")
        
        data_choice = input("Chá»n (1-2): ").strip()
        
        dataset_names = None
        if data_choice == '2':
            dataset_name = input("Nháº­p tÃªn dataset (username/dataset-name): ").strip()
            if dataset_name:
                dataset_names = [dataset_name]
        
        success = trainer.run_full_pipeline(dataset_names)
        if success:
            print("ğŸ‰ HOÃ€N THÃ€NH!")
        else:
            print("âŒ THáº¤T Báº I!")
    
    elif choice == '2':
        # Chá»‰ táº£i dá»¯ liá»‡u
        try:
            data_file = trainer.prepare_data_from_kaggle()
            print(f"âœ… Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng: {data_file}")
        except Exception as e:
            print(f"âŒ Lá»—i: {e}")
    
    elif choice == '3':
        # Training vá»›i dá»¯ liá»‡u cÃ³ sáºµn
        training_data_dir = os.path.join(trainer.base_dir, 'training_data')
        json_files = [f for f in os.listdir(training_data_dir) if f.endswith('.json')]
        
        if not json_files:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u nÃ o")
        else:
            print(f"\nğŸ“‹ TÃ¬m tháº¥y {len(json_files)} file dá»¯ liá»‡u:")
            for i, file in enumerate(json_files, 1):
                print(f"  {i}. {file}")
            
            try:
                file_idx = int(input("Chá»n file (sá»‘): ")) - 1
                if 0 <= file_idx < len(json_files):
                    data_file = os.path.join(training_data_dir, json_files[file_idx])
                    config = trainer.create_han_training_config(data_file)
                    success = trainer.start_han_training(config)
                    print("âœ… HOÃ€N THÃ€NH!" if success else "âŒ THáº¤T Báº I!")
                else:
                    print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡")
            except ValueError:
                print("âŒ Vui lÃ²ng nháº­p sá»‘")
    
    elif choice == '4':
        # Kiá»ƒm tra dá»¯ liá»‡u
        training_data_dir = os.path.join(trainer.base_dir, 'training_data')
        json_files = [f for f in os.listdir(training_data_dir) if f.endswith('.json')]
        
        if not json_files:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u nÃ o")
        else:
            for file in json_files:
                print(f"\nğŸ” Kiá»ƒm tra file: {file}")
                data_file = os.path.join(training_data_dir, file)
                trainer.validate_data_for_han(data_file)
    
    else:
        print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
